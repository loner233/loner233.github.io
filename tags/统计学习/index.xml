<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>统计学习 on Castle of Glass</title>
    <link>http://loner233.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 统计学习 on Castle of Glass</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en</language>
    <lastBuildDate>Sun, 11 Oct 2020 14:38:09 +0800</lastBuildDate><atom:link href="http://loner233.github.io/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>极大似然估计</title>
      <link>http://loner233.github.io/post/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</link>
      <pubDate>Sun, 11 Oct 2020 14:38:09 +0800</pubDate>
      
      <guid>http://loner233.github.io/post/%E6%9E%81%E5%A4%A7%E4%BC%BC%E7%84%B6%E4%BC%B0%E8%AE%A1/</guid>
      <description>&lt;h2 id=&#34;似然函数&#34;&gt;似然函数&lt;/h2&gt;
&lt;p&gt;似然和概率有非常大的相似点，但是有一个最为关键的不同点。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;似然是已知观测结果，来估计参数;而概率是已知参数，来估计观测&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>EM算法</title>
      <link>http://loner233.github.io/post/em%E7%AE%97%E6%B3%95/</link>
      <pubDate>Sun, 11 Oct 2020 14:29:34 +0800</pubDate>
      
      <guid>http://loner233.github.io/post/em%E7%AE%97%E6%B3%95/</guid>
      <description>&lt;p&gt;三枚硬币A，B，C,正面出现的概率分别是$\pi,p,q$,  &lt;strong&gt;先抛A，A正抛B，A反抛C，观测抛B\C的结果&lt;/strong&gt;重复n次，获得一个序列&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>重新理解贝叶斯公式</title>
      <link>http://loner233.github.io/post/%E9%87%8D%E6%96%B0%E7%90%86%E8%A7%A3%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/</link>
      <pubDate>Sun, 11 Oct 2020 11:37:21 +0800</pubDate>
      
      <guid>http://loner233.github.io/post/%E9%87%8D%E6%96%B0%E7%90%86%E8%A7%A3%E8%B4%9D%E5%8F%B6%E6%96%AF%E5%85%AC%E5%BC%8F/</guid>
      <description>&lt;p&gt;$$P(A|B)=\frac{P(B|A)}{P(B)}*P(A)$$&lt;/p&gt;
&lt;p&gt;以前一直理解贝叶斯公式为概率转换的，也就是先验，后验转换。现在看到了一种更好的解释&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>满条件分布</title>
      <link>http://loner233.github.io/post/%E6%BB%A1%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83/</link>
      <pubDate>Thu, 19 Sep 2019 09:24:10 +0800</pubDate>
      
      <guid>http://loner233.github.io/post/%E6%BB%A1%E6%9D%A1%E4%BB%B6%E5%88%86%E5%B8%83/</guid>
      <description>&lt;h3 id=&#34;mcmc方法的目标分布&#34;&gt;MCMC方法的目标分布&lt;/h3&gt;
&lt;p&gt;通常是多元联合概率分布$p(x) = p(x_1,x_2,&amp;hellip;,x_k)$,其中$x = (x_1,x_2,&amp;hellip;,x_k)^T$为$k$维随机变量&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
